# 容错性
无论您是否拥有自己的机器学习训练硬件，还是按小时租用它们，在这个不断加速的ML领域中，及时完成培训至关重要。因此，如果您在睡觉时其中一个GPU出现故障或检查点存储空间耗尽导致您的培训崩溃，那么当您醒来时可能会发现许多小时的培训时间已经丢失。由于ML硬件的高昂成本，很难像Web服务那样提供冗余故障转移解决方案。然而，实现培训的容错性是可行的，只需遵循几个简单的步骤即可。

大多数严肃的培训工作都是在SLURM环境中进行的，因此在本文中会频繁提到它，但本章中的大部分见解适用于任何其他培训环境。

## 始终计划比所需更多的节点
现实情况是GPU设备会出现故障。有时它们只是过热并关闭（可能可以恢复），而在另一些情况下，它们需要更换。随着时间的推移，使用同一批节点几周/几个月后，这种情况通常会有所改善，因为不良的节点会被逐渐替换掉。但是，如果幸运地收到一批新的GPU，特别是当技术刚刚推出时，预计其中相当大的一部分将出现问题。因此，如果您需要64个节点进行培训，请确保有备用节点可用，并研究如何在现有备用的不足够时快速替换故障节点。预测确切的冗余百分比并不容易，但5-10％应该不算过分。如果您需要在规定时间内完成培训，安全边际应更高。一旦有了可用的备用节点，验证您的SLURM环境是否会自动从池中移除问题节点，并将坏节点替换为好节点。如果您不使用SLURM调度程序，请验证它也能在不间断的情况下执行坏节点替换操作。此外，至少还需要一个额外的节点来运行各种预防性的看门狗（稍后在本章讨论）、可能的检查点卸载和清理作业。